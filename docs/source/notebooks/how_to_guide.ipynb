{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11fd331-df9a-402f-b1a8-6a78a03a372f",
   "metadata": {},
   "source": [
    "# How To Guide\n",
    "Currently all of these examples would require custom sql to be writen in Snowpark without the ice pick extension. With the ice pick extension we add the functionality to support new objects to Snowpark, and make the common tasks below easy to implement only using python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39661a6d-95f9-495b-a893-cb6504387674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing the extended session\n",
    "\n",
    "from ice_pick import extend_session\n",
    "from snowflake.snowpark import Session\n",
    "import configparser\n",
    "\n",
    "# Create the connection and extend the session with ice_pick\n",
    "# assumes credentials are in \"snowflake_creds.config\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read('snowflake_creds.config')\n",
    "session = extend_session(Session).builder.configs(dict(config['DEFAULT'])).create()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538900e7-b3ae-49d6-969a-1af820ae1a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1cdb7-1ded-4fbc-835f-7e5fca0ebb0a",
   "metadata": {},
   "source": [
    "### Get DDL of objects\n",
    "You can easily get ddl of all objects in your database by using the schema object filter. The schema object filter will return all objects matching the regular expresson provided. Wildcards (\".*\") can be used for all fields to get all objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ffba7b-509c-4633-bada-2c84c37f6eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'create or replace TABLE CUSTOMER (\\n\\tC_CUSTKEY NUMBER(38,0),\\n\\tC_NAME VARCHAR(25),\\n\\tC_ADDRESS VARCHAR(40),\\n\\tC_NATIONKEY NUMBER(38,0),\\n\\tC_PHONE VARCHAR(15),\\n\\tC_ACCTBAL NUMBER(12,2),\\n\\tC_MKTSEGMENT VARCHAR(10),\\n\\tC_COMMENT VARCHAR(117)\\n);'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ddl as a string for a single object\n",
    "\n",
    "# session.create_schema_object(database, schema, object name, object type)\n",
    "customer_table = session.create_schema_object('TEST', 'SCHEMA_1', 'CUSTOMER', 'TABLE')\n",
    "\n",
    "customer_table.get_ddl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78acd15-ccb6-4890-906c-00b3459042ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned_objects: 7\n",
      "first 5 object names and types:\n",
      "    ['TEST.SCHEMA_1.SP_PI()', 'TEST.SCHEMA_1.CUSTOMER', 'TEST.SCHEMA_1.LINEITEM', 'TEST.SCHEMA_2.CUSTOMER', 'TEST.SCHEMA_2.LINEITEM']\n"
     ]
    }
   ],
   "source": [
    "# Get many objects using a filter\n",
    "\n",
    "# session.create_schema_object_filter([database], [schema], [object name], [object type])\n",
    "all_schema_objects = session.create_schema_object_filter([\".*\"], [\".*\"], [\".*\"], [\".*\"])\n",
    "\n",
    "all_schema_object_list = all_schema_objects.return_schema_objects()\n",
    "\n",
    "print(f\"returned_objects: {len(all_schema_object_list)}\")\n",
    "print(f\"\"\"first 5 object names and types:\n",
    "    {\n",
    "        [f\"{obj.database}.{obj.schema}.{obj.object_name}\" \n",
    "        for obj in all_schema_object_list[0:5]]\n",
    "      }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d46868-6a64-4214-8a7f-7cdb4399be01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Object: TEST.SCHEMA_1.SP_PI()\n",
      "To Path: DDL/TEST/SCHEMA_1/PROCEDURE/TEST.SCHEMA_1.SP_PI().sql\n",
      "Saving Object: TEST.SCHEMA_1.CUSTOMER\n",
      "To Path: DDL/TEST/SCHEMA_1/TABLE/TEST.SCHEMA_1.CUSTOMER.sql\n",
      "Saving Object: TEST.SCHEMA_1.LINEITEM\n",
      "To Path: DDL/TEST/SCHEMA_1/TABLE/TEST.SCHEMA_1.LINEITEM.sql\n",
      "Saving Object: TEST.SCHEMA_2.CUSTOMER\n",
      "To Path: DDL/TEST/SCHEMA_2/TABLE/TEST.SCHEMA_2.CUSTOMER.sql\n",
      "Saving Object: TEST.SCHEMA_2.LINEITEM\n",
      "To Path: DDL/TEST/SCHEMA_2/TABLE/TEST.SCHEMA_2.LINEITEM.sql\n",
      "Saving Object: TEST_2.SCHEMA_A.CUSTOMER\n",
      "To Path: DDL/TEST_2/SCHEMA_A/TABLE/TEST_2.SCHEMA_A.CUSTOMER.sql\n",
      "Saving Object: TEST.SCHEMA_1.ECHO_VARCHAR(VARCHAR)\n",
      "To Path: DDL/TEST/SCHEMA_1/USER FUNCTION/TEST.SCHEMA_1.ECHO_VARCHAR(VARCHAR).sql\n"
     ]
    }
   ],
   "source": [
    "# Saving all the schema objects from the filter\n",
    "\n",
    "for obj in all_schema_object_list:\n",
    "    print(f\"Saving Object: {obj.database}.{obj.schema}.{obj.object_name}\")\n",
    "    \n",
    "    print(f\"To Path: DDL/{obj.database}/{obj.schema}/{obj.object_type}/\\\n",
    "{obj.database}.{obj.schema}.{obj.object_name}.sql\")\n",
    "    \n",
    "    obj.get_ddl(save=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc9c3b-7624-4e25-970d-58d1727913fa",
   "metadata": {},
   "source": [
    "Example of saved DDL for TEST.SCHEMA_1.SP_PI().sql:\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE PROCEDURE \"SP_PI\"()\n",
    "RETURNS FLOAT\n",
    "LANGUAGE JAVASCRIPT\n",
    "EXECUTE AS OWNER\n",
    "AS '\n",
    "    return 3.1415926;\n",
    "    ';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fed0bb-5c2a-4b93-8ac6-ccc627bbdf90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check access to an object (user privileges)\n",
    "Access to objects can be found in the Snowflake UI. However, if you are just accessing Snowflake with Snowpark it can be easier to verify privilegs programatically. To view all privileges we need to recusively search through the role heirarchy, but ice pick takes care of this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f339ebc5-5ed4-4e69-be9e-ded28690cc7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User PRESTONT4 has privileges: ['OWNERSHIP'] \n",
      "      on object TEST.SCHEMA_1.CUSTOMER \n"
     ]
    }
   ],
   "source": [
    "user = session.User(\"PRESTONT4\")\n",
    "\n",
    "object_to_check = session.create_schema_object('TEST', 'SCHEMA_1', 'CUSTOMER', 'TABLE')\n",
    "\n",
    "privileges = user.check_privilege(object_to_check)\n",
    "\n",
    "print(f\"\"\"User {user.name} has privileges: {privileges} \n",
    "      on object {object_to_check.database}.{object_to_check.schema}.{object_to_check.object_name} \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c1179-8b5e-4bde-99b8-5ff3791ac8dc",
   "metadata": {},
   "source": [
    "### Manage and optimize account resources like warehouses\n",
    "We can use the Warehouse object to view stats like usage on the warehouse and size the warhouse up or down. With the resize_recommendation() method we use some simple rules (like local disk spillage of queries) to make resizing recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ded16a-3097-41fb-bde1-d61db9a8029a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest 5 queries: ['01abb8c0-0001-9954-001b-13870005e1e2'\n",
      " '01abb8c0-0001-99a0-001b-138700065092'\n",
      " '01abb8c0-0001-9965-001b-13870006d022'\n",
      " '01abb8c0-0001-9980-001b-13870005c226'\n",
      " '01abb8bf-0001-99b7-001b-13870006c022'] \n",
      "\n",
      "Resize recommendation: Size Down\n",
      "Resize execution: Statement executed successfully.\n"
     ]
    }
   ],
   "source": [
    "warehouse = session.Warehouse(\"COMPUTE_WH\")\n",
    "\n",
    "# view warehouse query history for the last 5 hours\n",
    "query_hist_df = warehouse.query_history(5, 0, interval='hour')\n",
    "print(f\"Latest 5 queries: {query_hist_df['QUERY_ID'].values[0:5]} \\n\")\n",
    "\n",
    "# get warehouse optimization recommendations based on warehouse usage\n",
    "recommendation = warehouse.resize_recommendation(auto_apply = False)\n",
    "print(f\"Resize recommendation: {recommendation}\")\n",
    "\n",
    "# resize the warehouse to a \"small\" size based on the recommendation\n",
    "resize_status = warehouse.resize(\"SMALL\")\n",
    "print(f\"Resize execution: {resize_status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6aba77-9e0f-44fd-891f-a6c25d29cdf0",
   "metadata": {},
   "source": [
    "### Handle edge cases that Snowpark API does not support\n",
    "- Additional higher level functions support pandas functions like concat and melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5c1b07-2440-4b77-8b8c-72b9d2715f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"A\"   |\"B\"    |\"C\"        |\"D\"        |\n",
      "----------------------------------------\n",
      "|1.0   |snow   |NULL       |NULL       |\n",
      "|3.0   |flake  |NULL       |NULL       |\n",
      "|2.0   |NULL   |ice        |NULL       |\n",
      "|4.0   |NULL   |pick       |NULL       |\n",
      "|6.0   |NULL   |test_1     |NULL       |\n",
      "|7.0   |NULL   |test_2     |NULL       |\n",
      "|NULL  |NULL   |testing_d  |testing_f  |\n",
      "|NULL  |NULL   |testing_g  |testing_h  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concat example\n",
    "# This is useful becasuse the default Snowpark union cannot handle mismathced column name\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructField, StructType, FloatType, NullType\n",
    "\n",
    "schema_1 = StructType([StructField(\"a\", IntegerType()), StructField(\"b\", StringType())])\n",
    "schema_2 = StructType([StructField(\"a\", FloatType()), StructField(\"c\", StringType())])\n",
    "schema_3 = StructType([StructField(\"a\", IntegerType()), StructField(\"c\", StringType())])\n",
    "schema_4 = StructType([StructField(\"c\", StringType()), StructField(\"d\", StringType())])\n",
    "\n",
    "\n",
    "df_1 = session.create_dataframe([[1, \"snow\"], [3, \"flake\"]], schema_1)\n",
    "df_2 = session.create_dataframe([[2.0, \"ice\"], [4.0, \"pick\"]], schema_2)\n",
    "df_3 = session.create_dataframe([[6, \"test_1\"], [7, \"test_2\"]], schema_3)\n",
    "df_4 = session.create_dataframe([[\"testing_d\", \"testing_f\"], [\"testing_g\", \"testing_h\"]], schema_4)\n",
    "\n",
    "union_dfs = [df_1, df_2, df_3, df_4]\n",
    "\n",
    "unioned_df = session.concat(union_dfs)\n",
    "\n",
    "unioned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c334df2-d252-4988-af6e-b1b60e8d84a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "|\"A\"  |\"VALUE\"  |\"VARIABLE\"  |\n",
      "------------------------------\n",
      "|a    |1        |B           |\n",
      "|b    |3        |B           |\n",
      "|c    |5        |B           |\n",
      "|a    |2        |C           |\n",
      "|b    |4        |C           |\n",
      "|c    |6        |C           |\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Melt example\n",
    "# Currenlty Snowpark doesn't have function like melt\n",
    "\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructField, StructType, FloatType, NullType\n",
    "\n",
    "schema = StructType([StructField(\"A\", StringType()), StructField(\"B\", IntegerType()), StructField(\"C\", IntegerType())])\n",
    "df = session.create_dataframe([['a', 1, 2], ['b', 3, 4], ['c', 5, 6]], schema)\n",
    "\n",
    "melt_df = session.melt(df, ['A'], ['B', 'C'])\n",
    "melt_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
